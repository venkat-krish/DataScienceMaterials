{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP02-Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/Z4WTvCtz1XK6SFQbVH/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkat-krish/DataScienceMaterials/blob/master/NLP02_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LcBV9lF9UO-",
        "outputId": "a93ba458-858e-475a-b47b-7ca35ed6b7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data preprocessing libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "from gensim.models import Word2Vec # Word2Vec module\n",
        "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, remove_stopwords, strip_numeric, stem_text\n",
        "\n",
        "#Feature engineering\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "1DE3ila5B0mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['Tweet ID', 'Entity', 'Sentiment', 'Tweets']\n",
        "# Twitter data\n",
        "twitter_df = pd.read_csv(\"/content/sample_data/twitter_training.csv\", names=cols)\n",
        "\n",
        "print(twitter_df.head())\n",
        "twitter_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljXDWgnxBukw",
        "outputId": "65ea24ed-34ff-40b1-f02e-1ef35e514ae6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Tweet ID       Entity Sentiment  \\\n",
            "0      2401  Borderlands  Positive   \n",
            "1      2401  Borderlands  Positive   \n",
            "2      2401  Borderlands  Positive   \n",
            "3      2401  Borderlands  Positive   \n",
            "4      2401  Borderlands  Positive   \n",
            "\n",
            "                                              Tweets  \n",
            "0  im getting on borderlands and i will murder yo...  \n",
            "1  I am coming to the borders and I will kill you...  \n",
            "2  im getting on borderlands and i will kill you ...  \n",
            "3  im coming on borderlands and i will murder you...  \n",
            "4  im getting on borderlands 2 and i will murder ...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74682 entries, 0 to 74681\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Tweet ID   74682 non-null  int64 \n",
            " 1   Entity     74682 non-null  object\n",
            " 2   Sentiment  74682 non-null  object\n",
            " 3   Tweets     73996 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 2.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjJvi-PICbO1",
        "outputId": "2833a288-06cc-4e9f-92aa-d7f5bfbb7144"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tweet ID       0\n",
              "Entity         0\n",
              "Sentiment      0\n",
              "Tweets       686\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing null records\n",
        "twitter_df = twitter_df.dropna(axis=0)"
      ],
      "metadata": {
        "id": "AR05jmllChI6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_df.info()\n",
        "print(twitter_df['Entity'].value_counts())\n",
        "twitter_df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuxNA6eFDNWL",
        "outputId": "979fad21-816a-4b8e-da95-9d6a031fbd39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 73996 entries, 0 to 74681\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Tweet ID   73996 non-null  int64 \n",
            " 1   Entity     73996 non-null  object\n",
            " 2   Sentiment  73996 non-null  object\n",
            " 3   Tweets     73996 non-null  object\n",
            " 4   Processed  73996 non-null  object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 3.4+ MB\n",
            "MaddenNFL                            2377\n",
            "LeagueOfLegends                      2377\n",
            "CallOfDuty                           2376\n",
            "Verizon                              2365\n",
            "TomClancysRainbowSix                 2364\n",
            "Facebook                             2362\n",
            "Microsoft                            2361\n",
            "Dota2                                2359\n",
            "WorldOfCraft                         2357\n",
            "ApexLegends                          2353\n",
            "NBA2K                                2343\n",
            "CallOfDutyBlackopsColdWar            2343\n",
            "FIFA                                 2324\n",
            "johnson&johnson                      2324\n",
            "TomClancysGhostRecon                 2321\n",
            "Battlefield                          2316\n",
            "Overwatch                            2316\n",
            "GrandTheftAuto(GTA)                  2293\n",
            "HomeDepot                            2292\n",
            "PlayStation5(PS5)                    2291\n",
            "Hearthstone                          2286\n",
            "CS-GO                                2284\n",
            "Xbox(Xseries)                        2283\n",
            "Borderlands                          2280\n",
            "Amazon                               2276\n",
            "Google                               2274\n",
            "Nvidia                               2271\n",
            "Cyberpunk2077                        2262\n",
            "RedDeadRedemption(RDR)               2249\n",
            "Fortnite                             2249\n",
            "PlayerUnknownsBattlegrounds(PUBG)    2234\n",
            "AssassinsCreed                       2234\n",
            "Name: Entity, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Negative      22358\n",
              "Positive      20655\n",
              "Neutral       18108\n",
              "Irrelevant    12875\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3ZSU6JsnDOsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n"
      ],
      "metadata": {
        "id": "FudB2_8aDa1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemmer object\n",
        "porter = PorterStemmer()\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "class DataPreprocess:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.filters = [strip_tags,\n",
        "                       strip_numeric,\n",
        "                      #  strip_punctuation,\n",
        "                       lambda x: x.lower(),\n",
        "                        lambda x: re.sub(r'[^a-zA-Z#]', ' ', x),\n",
        "                      #  lambda x: re.sub(r'\\s+\\w{1}\\s+', '', x),\n",
        "                       remove_stopwords]\n",
        "    def __call__(self, doc):\n",
        "        clean_words = self.__apply_filter(doc)\n",
        "        return clean_words\n",
        "    \n",
        "    def __apply_filter(self, doc):\n",
        "        try:\n",
        "            cleanse_words = set(preprocess_string(doc, self.filters))\n",
        "#             filtered_words = set(wnl.lemmatize(w) if w.endswith('e') or w.endswith('y') else porter.stem(w) for w in cleanse_words)\n",
        "            return ' '.join(cleanse_words)\n",
        "        except TypeError as te:\n",
        "            raise(TypeError(\"Not a valid data {}\".format(te)))"
      ],
      "metadata": {
        "id": "MIaCbPIVDceo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the text data and make the corpus cleansed\n",
        "twitter_df['Processed'] = twitter_df['Tweets'].apply(DataPreprocess())"
      ],
      "metadata": {
        "id": "BGDBny70D6Fy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_df['Processed'][0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nrr_89lEEN_",
        "outputId": "8f246dd7-0283-409a-f962-3cd92f323109"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        getting im borderlands murder\n",
              "1                                  borders coming kill\n",
              "2                          getting im borderlands kill\n",
              "3                         im coming borderlands murder\n",
              "4                        getting im borderlands murder\n",
              "5                        getting im borderlands murder\n",
              "6    pc t favorite mlsiwfjg wallpaper enjoy making ...\n",
              "7    pc t favorite mlsiwfjg wallpaper borderlands k...\n",
              "8    fun fan hours t favorite huge spent know m cha...\n",
              "9    rhandlerr pc t favorite mlsiwfjg wallpaper enj...\n",
              "Name: Processed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "fDCUKMSVD3H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(vector, X_train, X_test):\n",
        "    vector_fit = vector.fit(X_train)\n",
        "    \n",
        "    X_train_vec = vector_fit.transform(X_train)\n",
        "    X_test_vec = vector_fit.transform(X_test)\n",
        "    \n",
        "    print(\"Vectorization is completed.\")\n",
        "    return X_train_vec, X_test_vec\n",
        "\n",
        "def label_encoding(y_train):\n",
        "    \"\"\"\n",
        "        Encode the given list of class labels\n",
        "        :y_train_enc: returns list of encoded classes\n",
        "        :labels: actual class labels\n",
        "    \"\"\"\n",
        "    lbl_enc = LabelEncoder()\n",
        "    \n",
        "    y_train_enc = lbl_enc.fit_transform(y_train)\n",
        "    labels = lbl_enc.classes_\n",
        "    \n",
        "    return y_train_enc, labels"
      ],
      "metadata": {
        "id": "Me-hg5ZhDgNZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = twitter_df['Tweets']\n",
        "y = twitter_df['Sentiment']\n",
        "\n",
        "# Label encoding on the classes\n",
        "y_enc_train, labels = label_encoding(y)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y_enc_train, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "GqJybWeWEh08"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8igCeTrEkjO",
        "outputId": "22877567-ad23-4db9-b34a-5d6e07700259"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59196,) (14800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# BOW vectorizer\n",
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "X_train_vec, X_valid_vec = vectorize(bow_vectorizer, X_train, X_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id9EJbIOE0pO",
        "outputId": "1362e46e-b8a6-4584-b8fa-ce76b240e97e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization is completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_classweights(target):\n",
        "    \"\"\"\n",
        "    Computes the weights of the target values based on the samples\n",
        "    :param target: Y-target variable\n",
        "    :return: dictionary object\n",
        "    \"\"\"\n",
        "    # compute class weights\n",
        "    class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(target), y=target)\n",
        "    \n",
        "    # make the class weight list into dictionary\n",
        "    weights = {}\n",
        "    \n",
        "    # enumerate the list\n",
        "    for index, weight in enumerate(class_weights):\n",
        "        weights[index] = weight\n",
        "        \n",
        "    return weights\n",
        "\n",
        "# Get the class weights for the target variable\n",
        "weights = compute_classweights(y_train)"
      ],
      "metadata": {
        "id": "FaIicSljE4vS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB classifier\n",
        "xgb_params = {\n",
        "    'max_depth': 7,\n",
        "    'n_estimators': 1000,\n",
        "    'lambda': 0.01,\n",
        "    'class_weight': weights\n",
        "}\n",
        "\n",
        "xgb_clf = XGBClassifier(**xgb_params)\n",
        "\n",
        "xgb_clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH3jCejwFAT0",
        "outputId": "ff5ecdc2-fd78-4232-ac5b-37b6cc68152b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(class_weight={0: 1.431237911025145, 1: 0.82856502995353,\n",
              "                            2: 1.0221715706589307, 3: 0.8959859538657141},\n",
              "              lambda=0.01, max_depth=7, n_estimators=1000,\n",
              "              objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on the validation set\n",
        "y_pred = xgb_clf.predict(X_valid_vec)\n",
        "\n",
        "\n",
        "print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\tF1-Score: %1.3f\\n\" % (accuracy_score(y_valid, y_pred), precision_score(y_valid, y_pred, average='micro'), recall_score(y_valid, y_pred, average='micro'), f1_score(y_valid, y_pred, average='micro')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAp9zR-MFLdg",
        "outputId": "c753c277-f26d-42bc-b099-f3a6b8b0bd06"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.738 \tPrecision: 0.738 \tRecall: 0.738 \tF1-Score: 0.738\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fJYsZdrDFeT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}